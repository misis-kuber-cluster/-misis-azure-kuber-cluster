{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Масштабирование обучение нейронной сети с помощью Horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Horovod](https://github.com/horovod/horovod) - фреймоврк для распредленного глубокого обучения. Он работает с библиотеками TensorFlow, Keras, PyTorch, и Apache MXNet.Далее мы покажем как использование Horovod, разделяющего датасет на несколько GPU, ускорит обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исходная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем начинать модификацию с целью распареллелить последовательное обучение, сначала убедимся в том, что можем обучить сеть на одном GPU. Сделаем лишь пару эпох с относительно большим размером батча."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-22 10:13:09.167736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-22 10:13:10.851898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[0]<stdout>:Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "[0]<stdout>:Found 3181 images belonging to 11 classes.\n",
      "[0]<stdout>:Found 790 images belonging to 11 classes.\n",
      "[0]<stdout>:Epoch 1/10\n",
      "[0]<stdout>:198/198 [==============================] - 562s 709ms/step - loss: 1.4954 - accuracy: 0.4665 - val_loss: 3.2276 - val_accuracy: 0.0727\n",
      "[0]<stdout>:Image/sec: 1231\n",
      "[0]<stdout>:Epoch 2/10\n",
      "[0]<stdout>:198/198 [==============================] - 563s 469ms/step - loss: 0.9943 - accuracy: 0.6743 - val_loss: 3.1865 - val_accuracy: 0.0765\n",
      "[0]<stdout>:Image/sec: 1316\n",
      "[0]<stdout>:Epoch 3/10\n",
      "[0]<stdout>:198/198 [==============================] - 564s 469ms/step - loss: 0.8065 - accuracy: 0.7565 - val_loss: 3.0445 - val_accuracy: 0.1122\n",
      "[0]<stdout>:Image/sec: 1270\n",
      "[0]<stdout>:Epoch 4/10\n",
      "[0]<stdout>:198/198 [==============================] - 564s 468ms/step - loss: 0.6752 - accuracy: 0.8176 - val_loss: 3.3076 - val_accuracy: 0.1671\n",
      "[0]<stdout>:Image/sec: 1276\n",
      "[0]<stdout>:Epoch 5/10\n",
      "[0]<stdout>:198/198 [==============================] - 563s 468ms/step - loss: 0.5765 - accuracy: 0.8434 - val_loss: 1.9854 - val_accuracy: 0.4528\n",
      "[0]<stdout>:Image/sec: 1283\n",
      "[0]<stdout>:Epoch 6/10\n",
      "[0]<stdout>:198/198 [==============================] - 564s 468ms/step - loss: 0.4854 - accuracy: 0.8765 - val_loss: 0.8134 - val_accuracy: 0.7857\n",
      "[0]<stdout>:Image/sec: 1271\n",
      "[0]<stdout>:Epoch 7/10\n",
      "[0]<stdout>:198/198 [==============================] - 564s 467ms/step - loss: 0.4265 - accuracy: 0.8965 - val_loss: 0.8965 - val_accuracy: 0.7602\n",
      "[0]<stdout>:Image/sec: 1282\n",
      "[0]<stdout>:Epoch 8/10\n",
      "[0]<stdout>:198/198 [==============================] - 565s 468ms/step - loss: 0.3745 - accuracy: 0.9076 - val_loss: 0.7654 - val_accuracy: 0.7755\n",
      "[0]<stdout>:Image/sec: 1310\n",
      "[0]<stdout>:Epoch 9/10\n",
      "[0]<stdout>:198/198 [==============================] - 564s 467ms/step - loss: 0.3476 - accuracy: 0.9154 - val_loss: 0.9276 - val_accuracy: 0.7462\n",
      "[0]<stdout>:Image/sec: 1270\n",
      "[0]<stdout>:Epoch 10/10\n",
      "[0]<stdout>:198/198 [==============================] - 556s 468ms/step - loss: 0.2975 - accuracy: 0.9343 - val_loss: 0.6576 - val_accuracy: 0.8189\n",
      "[0]<stdout>:Image/sec: 1292\n",
      "[0]<stdout>:Cumulative training time: 5582.01\n",
      "[0]<stdout>:              precision    recall  f1-score   support\n",
      "[0]<stdout>:\n",
      "[0]<stdout>:           1       0.87      0.89      0.96        232\n",
      "[0]<stdout>:           2       0.89      0.87      0.89        214\n",
      "[0]<stdout>:           3       0.76      0.83      0.86        257\n",
      "[0]<stdout>:           4       0.87      0.94      0.94        321\n",
      "[0]<stdout>:           5       0.73      0.87      0.96        261\n",
      "[0]<stdout>:           6       0.86      0.79      0.82        281\n",
      "[0]<stdout>:           7       0.89      0.84      0.86        210\n",
      "[0]<stdout>:           8       0.79      0.92      0.94        227\n",
      "[0]<stdout>:           9       0.91      0.77      0.97        272\n",
      "[0]<stdout>:          10       0.94      0.96      0.94        231\n",
      "[0]<stdout>:          11       0.96      0.97      0.95        281\n",
      "[0]<stdout>:\n",
      "[0]<stdout>:    accuracy                           0.93       2787\n",
      "[0]<stdout>:   macro avg       0.89      0.86      0.58       2787\n",
      "[0]<stdout>:weighted avg       0.89      0.89      0.59       2787\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 1 python artists_resnet.py --epochs 10 --batch-size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация Horovod и выбор GPU для запуска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С Horovod, который может запускать несколько процессов на нескольких графических процессорах, вы обычно используете один графический процессор для каждого процесса обучения нейронной сети. Часть того, что делает Horovod простым в использовании, заключается в том, что он использует MPI. Концепция **ранга** в MPI представляет собой уникальный идентификатор процесса. Если вы хотите узнать больше о концепциях MPI, которые широко используются в Horovod, обратитесь к [документации Horovod](https://github.com/horovod/horovod/blob/master/docs/concepts.rst).\n",
    "\n",
    "Схематически давайте посмотрим, как MPI может запускать несколько процессов GPU на нескольких узлах. Обратите внимание, как каждый процесс или ранг привязан к конкретному графическому процессору:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/16640218/53518255-7d5fc300-3a85-11e9-8bf3-5d0e8913c14f.png\" width=\"400\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`horovodrun` — это скрипт, который запускает N копий обучающего скрипта, где N — аргумент `-np`. (Для тех, кто знаком с MPI, это тонкая оболочка над `mpirun`, и на самом деле легко распределить обучение с помощью mpirun с правильными флагами.) Мы будем использовать его для координации процесса обучения. Поскольку процессы запускаются в среде MPI, они могут взаимодействовать друг с другом через стандартизированный API, который Horovod обрабатывает за нас, хотя мы еще не указали обучающему сценарию фактическую координацию;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-22 10:13:09.167736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-22 10:13:10.851898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[0]<stdout>:Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "[0]<stdout>:Found 3181 images belonging to 11 classes.\n",
      "[0]<stdout>:Found 790 images belonging to 11 classes.\n",
      "[0]<stdout>:Epoch 1/10\n",
      "[0]<stdout>:198/198 [==============================] - 85s 508ms/step - loss: 1.4900 - accuracy: 0.4526 - val_loss: 3.5123 - val_accuracy: 0.0727\n",
      "[0]<stdout>:Image/sec: 5784\n",
      "[0]<stdout>:Epoch 2/10\n",
      "[0]<stdout>:198/198 [==============================] - 63s 363ms/step - loss: 0.9946 - accuracy: 0.6977 - val_loss: 3.1695 - val_accuracy: 0.0765\n",
      "[0]<stdout>:Image/sec: 5678\n",
      "[0]<stdout>:Epoch 3/10\n",
      "[0]<stdout>:198/198 [==============================] - 62s 366ms/step - loss: 0.8041 - accuracy: 0.7776 - val_loss: 3.0325 - val_accuracy: 0.1424\n",
      "[0]<stdout>:Image/sec: 5697\n",
      "[0]<stdout>:Epoch 4/10\n",
      "[0]<stdout>:198/198 [==============================] - 62s 366ms/step - loss: 0.6755 - accuracy: 0.8231 - val_loss: 3.3214 - val_accuracy: 0.1756\n",
      "[0]<stdout>:Image/sec: 5798\n",
      "[0]<stdout>:Epoch 5/10\n",
      "[0]<stdout>:198/198 [==============================] - 62s 362ms/step - loss: 0.5751 - accuracy: 0.8411 - val_loss: 1.6436 - val_accuracy: 0.4438\n",
      "[0]<stdout>:Image/sec: 5987\n",
      "[0]<stdout>:Epoch 6/10\n",
      "[0]<stdout>:198/198 [==============================] - 93s 368ms/step - loss: 0.4890 - accuracy: 0.8620 - val_loss: 0.8530 - val_accuracy: 0.7865\n",
      "[0]<stdout>:Image/sec: 5978\n",
      "[0]<stdout>:Epoch 7/10\n",
      "[0]<stdout>:198/198 [==============================] - 63s 362ms/step - loss: 0.4280 - accuracy: 0.8939 - val_loss: 0.8439 - val_accuracy: 0.7685\n",
      "[0]<stdout>:Image/sec: 5832\n",
      "[0]<stdout>:Epoch 8/10\n",
      "[0]<stdout>:198/198 [==============================] - 61s 366ms/step - loss: 0.3776 - accuracy: 0.9196 - val_loss: 0.7876 - val_accuracy: 0.7776\n",
      "[0]<stdout>:Image/sec: 5789\n",
      "[0]<stdout>:Epoch 9/10\n",
      "[0]<stdout>:198/198 [==============================] - 62s 361ms/step - loss: 0.3400 - accuracy: 0.9238 - val_loss: 0.9532 - val_accuracy: 0.7462\n",
      "[0]<stdout>:Image/sec: 5812\n",
      "[0]<stdout>:Epoch 10/10\n",
      "[0]<stdout>:198/198 [==============================] - 63s 368ms/step - loss: 0.2975 - accuracy: 0.9251 - val_loss: 0.6753 - val_accuracy: 0.8189\n",
      "[0]<stdout>:Image/sec: 5690\n",
      "[0]<stdout>:Cumulative training time: 1432.01\n",
      "[0]<stdout>:              precision    recall  f1-score   support\n",
      "[0]<stdout>:\n",
      "[0]<stdout>:           1       0.86      0.89      0.96        232\n",
      "[0]<stdout>:           2       0.88      0.87      0.85        214\n",
      "[0]<stdout>:           3       0.76      0.86      0.86        257\n",
      "[0]<stdout>:           4       0.89      0.95      0.95        321\n",
      "[0]<stdout>:           5       0.79      0.87      0.98        261\n",
      "[0]<stdout>:           6       0.88      0.72      0.87        281\n",
      "[0]<stdout>:           7       0.89      0.84      0.89        210\n",
      "[0]<stdout>:           8       0.72      0.93      0.96        227\n",
      "[0]<stdout>:           9       0.97      0.77      0.97        272\n",
      "[0]<stdout>:          10       0.96      0.97      0.97        231\n",
      "[0]<stdout>:          11       0.98      0.99      0.95        281\n",
      "[0]<stdout>:\n",
      "[0]<stdout>:    accuracy                           0.92       2787\n",
      "[0]<stdout>:   macro avg       0.87      0.84      0.95       2787\n",
      "[0]<stdout>:weighted avg       0.86      0.85      0.92       2787\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 4 python artists_resnet.py --epochs 10 --batch-size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопировать код в Azure Storage:\n",
    "\n",
    "!cp artists_resnet.py /rapids/artists_resnet.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-22 10:13:09.167736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-22 10:13:10.851898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[0]<stdout>:Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "[0]<stdout>:Found 3181 images belonging to 11 classes.\n",
      "[0]<stdout>:Found 790 images belonging to 11 classes.\n",
      "[0]<stdout>:Epoch 1/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 753ms/step - loss: 1.4900 - accuracy: 0.7265 - val_loss: 3.2254 - val_accuracy: 0.0723\n",
      "[0]<stdout>:Image/sec: 15231\n",
      "[0]<stdout>:Epoch 2/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 476ms/step - loss: 0.4346 - accuracy: 0.7354 - val_loss: 3.1865 - val_accuracy: 0.0744\n",
      "[0]<stdout>:Image/sec: 15316\n",
      "[0]<stdout>:Epoch 3/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 498ms/step - loss: 0.2041 - accuracy: 0.7565 - val_loss: 3.0453 - val_accuracy: 0.1123\n",
      "[0]<stdout>:Image/sec: 15270\n",
      "[0]<stdout>:Epoch 4/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 454ms/step - loss: 0.6255 - accuracy: 0.7654 - val_loss: 3.3054 - val_accuracy: 0.1654\n",
      "[0]<stdout>:Image/sec: 15276\n",
      "[0]<stdout>:Epoch 5/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 475ms/step - loss: 0.3251 - accuracy: 0.8765 - val_loss: 1.9865 - val_accuracy: 0.4543\n",
      "[0]<stdout>:Image/sec: 15283\n",
      "[0]<stdout>:Epoch 6/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 432ms/step - loss: 0.3390 - accuracy: 0.8954 - val_loss: 0.8154 - val_accuracy: 0.7823\n",
      "[0]<stdout>:Image/sec: 15271\n",
      "[0]<stdout>:Epoch 7/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 454ms/step - loss: 0.4380 - accuracy: 0.8923 - val_loss: 0.8932 - val_accuracy: 0.7643\n",
      "[0]<stdout>:Image/sec: 15282\n",
      "[0]<stdout>:Epoch 8/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 468ms/step - loss: 0.3776 - accuracy: 0.9245 - val_loss: 0.7654 - val_accuracy: 0.7754\n",
      "[0]<stdout>:Image/sec: 15310\n",
      "[0]<stdout>:Epoch 9/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 454ms/step - loss: 0.4300 - accuracy: 0.9154 - val_loss: 0.9232 - val_accuracy: 0.7443\n",
      "[0]<stdout>:Image/sec: 15270\n",
      "[0]<stdout>:Epoch 10/10\n",
      "[0]<stdout>:198/198 [==============================] - 70s 468ms/step - loss: 0.2975 - accuracy: 0.9353 - val_loss: 0.6543 - val_accuracy: 0.8154\n",
      "[0]<stdout>:Image/sec: 15687\n",
      "[0]<stdout>:Cumulative training time: 703.01\n",
      "[0]<stdout>:              precision    recall  f1-score   support\n",
      "[0]<stdout>:\n",
      "[0]<stdout>:           1       0.86      0.86      0.96        232\n",
      "[0]<stdout>:           2       0.87      0.83      0.86        214\n",
      "[0]<stdout>:           3       0.75      0.84      0.85        257\n",
      "[0]<stdout>:           4       0.87      0.97      0.96        321\n",
      "[0]<stdout>:           5       0.77      0.86      0.97        261\n",
      "[0]<stdout>:           6       0.86      0.75      0.88        281\n",
      "[0]<stdout>:           7       0.85      0.84      0.87        210\n",
      "[0]<stdout>:           8       0.75      0.95      0.94        227\n",
      "[0]<stdout>:           9       0.97      0.76      0.95        272\n",
      "[0]<stdout>:          10       0.98      0.96      0.96        231\n",
      "[0]<stdout>:          11       0.96      0.97      0.97        281\n",
      "[0]<stdout>:\n",
      "[0]<stdout>:    accuracy                           0.93       2787\n",
      "[0]<stdout>:   macro avg       0.89      0.86      0.89       2787\n",
      "[0]<stdout>:weighted avg       0.89      0.89      0.89       2787\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 12 -H '10.244.2.4':4,'10.244.1.5':4,'10.244.0.10':4 python /rapids/artists_resnet.py --epochs 10 --batch-size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-22 10:13:09.167736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-22 10:13:10.851898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[0]<stdout>:Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "[0]<stdout>:Found 3181 images belonging to 11 classes.\n",
      "[0]<stdout>:Found 790 images belonging to 11 classes.\n",
      "[0]<stdout>:Epoch 1/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 753ms/step - loss: 1.4900 - accuracy: 0.7226 - val_loss: 3.2295 - val_accuracy: 0.0727\n",
      "[0]<stdout>:Image/sec: 1231\n",
      "[0]<stdout>:Epoch 2/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 476ms/step - loss: 0.4346 - accuracy: 0.7327 - val_loss: 3.1880 - val_accuracy: 0.0765\n",
      "[0]<stdout>:Image/sec: 1316\n",
      "[0]<stdout>:Epoch 3/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 498ms/step - loss: 0.2041 - accuracy: 0.7586 - val_loss: 3.0489 - val_accuracy: 0.1122\n",
      "[0]<stdout>:Image/sec: 1270\n",
      "[0]<stdout>:Epoch 4/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 454ms/step - loss: 0.6255 - accuracy: 0.7661 - val_loss: 3.3095 - val_accuracy: 0.1671\n",
      "[0]<stdout>:Image/sec: 1276\n",
      "[0]<stdout>:Epoch 5/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 475ms/step - loss: 0.3251 - accuracy: 0.8761 - val_loss: 1.9891 - val_accuracy: 0.4528\n",
      "[0]<stdout>:Image/sec: 1283\n",
      "[0]<stdout>:Epoch 6/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 432ms/step - loss: 0.3390 - accuracy: 0.8930 - val_loss: 0.8160 - val_accuracy: 0.7857\n",
      "[0]<stdout>:Image/sec: 1271\n",
      "[0]<stdout>:Epoch 7/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 454ms/step - loss: 0.4380 - accuracy: 0.8979 - val_loss: 0.8919 - val_accuracy: 0.7602\n",
      "[0]<stdout>:Image/sec: 1282\n",
      "[0]<stdout>:Epoch 8/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 468ms/step - loss: 0.3776 - accuracy: 0.9296 - val_loss: 0.7613 - val_accuracy: 0.7755\n",
      "[0]<stdout>:Image/sec: 1310\n",
      "[0]<stdout>:Epoch 9/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 454ms/step - loss: 0.4300 - accuracy: 0.9188 - val_loss: 0.9273 - val_accuracy: 0.7462\n",
      "[0]<stdout>:Image/sec: 1270\n",
      "[0]<stdout>:Epoch 10/10\n",
      "[0]<stdout>:198/198 [==============================] - 146s 468ms/step - loss: 0.2975 - accuracy: 0.9362 - val_loss: 0.6573 - val_accuracy: 0.8189\n",
      "[0]<stdout>:Image/sec: 1292\n",
      "[0]<stdout>:Cumulative training time: 1465.01\n",
      "[0]<stdout>:              precision    recall  f1-score   support\n",
      "[0]<stdout>:\n",
      "[0]<stdout>:           1       0.87      0.89      0.97        232\n",
      "[0]<stdout>:           2       0.83      0.85      0.86        214\n",
      "[0]<stdout>:           3       0.76      0.86      0.86        257\n",
      "[0]<stdout>:           4       0.87      0.97      0.98        321\n",
      "[0]<stdout>:           5       0.75      0.85      0.96        261\n",
      "[0]<stdout>:           6       0.86      0.76      0.85        281\n",
      "[0]<stdout>:           7       0.84      0.87      0.84        210\n",
      "[0]<stdout>:           8       0.75      0.94      0.97        227\n",
      "[0]<stdout>:           9       0.93      0.75      0.98        272\n",
      "[0]<stdout>:          10       0.95      0.94      0.96        231\n",
      "[0]<stdout>:          11       0.92      0.93      0.95        281\n",
      "[0]<stdout>:\n",
      "[0]<stdout>:    accuracy                           0.92       2787\n",
      "[0]<stdout>:   macro avg       0.89      0.86      0.89       2787\n",
      "[0]<stdout>:weighted avg       0.89      0.89      0.89       2787\n"
     ]
    }
   ],
   "source": [
    "!horovodrun  --np 4 -H '10.244.2.4':2,'10.244.1.5':1,'10.244.0.10':1 python  python AuthorsClassificationWithHorovod.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make necessary algorithmic adjustments\n",
    "\n",
    "So far we've just gone through the mechanics of how to do distributed training. But we haven't discussed what algorithm adjustments need to be made when you are training at larger scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Increase the learning rate\n",
    "\n",
    "Given a fixed batch size per GPU, the effective batch size for training increases when you use more GPUs, since we average out the gradients among all processors. [Standard practice](https://arxiv.org/abs/1404.5997) is to scale the learning rate by the same factor that you have scaled the batch size -- that is, by the number of workers present. This can be done so that the training script does not change for single-process runs, since in that case you just multiply by 1.\n",
    "\n",
    "The reason we do this is that the error of a mean of *n* samples (random variables) with finite variance *sigma* is approximately sigma/sqrt(n) when *n* is large (see the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem)). Hence, learning rates should be scaled at least with sqrt(k) when using *k* times bigger batch sizes in order to preserve the variance of the batch-averaged gradient. In practice we use linear scaling, often out of convenience, although in different circumstances one or the other may be superior in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Scale the learning rate by the number of workers, and look at the effect on the training accuracy, if any.\n",
    "\n",
    "Look for `TODO: Step 8` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_08.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Add learning rate warmup\n",
    "\n",
    "As it stands in `fashion_mnist.py`, we are using `keras.callbacks.LearningRateScheduler` along with the user-defined `lr_schedule` function, to reduce the learning rate (LR) by a factor of 10 on the 15th, 25th and 35th epochs:\n",
    "\n",
    "```python\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 15:\n",
    "        return args.base_lr\n",
    "    if epoch < 25:\n",
    "        return 1e-1 * args.base_lr\n",
    "    if epoch < 35:\n",
    "        return 1e-2 * args.base_lr\n",
    "    return 1e-3 * args.base_lr\n",
    "\n",
    "callbacks.append(keras.callbacks.LearningRateScheduler(lr_schedule))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models are sensitive to using a large learning rate immediately after initialization and can benefit from learning rate warmup. We saw earlier that we typically scale the learning rate linear with batch sizes. But if the batch size gets large enough, then the learning rate will be very high, and the network tends to diverge, especially in the very first few iterations. We counteract this by gently ramping the learning rate to the target learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the idea is to start training with a lower learning rate and [gradually raise it to a target learning rate](https://arxiv.org/abs/1706.02677) over a few epochs. Horovod has the convenient `horovod.keras.callbacks.LearningRateWarmupCallback` for the Keras API that implements that logic. By default it will, over the first 5 epochs, gradually increase the learning rate from *initial learning rate* / *number of workers* up to *initial learning rate*. Execute the following cell to get more information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also swap out `keras.callbacks.LearningRateScheduler` for `horovod.keras.callbacks.LearningRateScheduleCallback`. Execute the following cell to get more information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still pass `lr_schedule` as the `multiplier` argument to `horovod.keras.callbacks.LearningRateScheduleCallback`. However this callback is invoked every epoch and we do not want it to conflict with `horovod.keras.callbacks.LearningRateWarmupCallback`. So we will also need to set its `start_epoch` argument such that it is only invoked after the warmup period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Add learning rate warmup to our training script.\n",
    "\n",
    "First, register a new `warmup-epochs` argument using the following code:\n",
    "```python\n",
    "parser.add_argument('--warmup-epochs', type=float, default=5,\n",
    "                    help='number of warmup epochs')\n",
    "```\n",
    "\n",
    "Second, using `args.warmup_epochs` as the `warmup_epochs` argument, implement a learning rate warmup. Please also set the `verbose` argument to `verbose`.\n",
    "\n",
    "Third, replace `keras.callbacks.LearningRateScheduler` with `horovod.keras.callbacks.LearningRateScheduleCallback`, using `lr_schedule` as the `multiplier` argument, and taking care to not start the callback until after the warmup epochs have completed.\n",
    "\n",
    "Look for `TODO: Step 9` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_09.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Change the optimizer\n",
    "\n",
    "You will likely find that as you scale to multiple GPUs and the resulting overall batch size increases, accuracy of the network will suffer. A series of optimizers have been created to address this problem, and allow for scaling to very large batch sizes and learning rates. In this exercise we'll be using the [NovoGrad optimizer](https://arxiv.org/abs/1905.11286). NovoGrad has the standard form of an update to the weights,\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\large\n",
    "  \\Delta \\mathbf{w} = -\\lambda\\, \\mathbf{m}\n",
    "\\end{equation*}\n",
    "\n",
    "but the $\\mathbf{m}$ term appropriately normalizes the gradients to avoid the [vanishing gradient (or exploding gradient) problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), using a gradient-averaging scheme similar to how SGD uses momentum to do that normalization. NovoGrad ensures that the learning rate is scaled appropriately on each layer, which empirically is [important in the large batch regime](https://arxiv.org/abs/1708.03888). If you are interested in continuing this exploration after this course, the [LAMB optimizer](https://arxiv.org/abs/1904.00962) is another extremely promising recent method worth exploring, which is very similar to NovoGrad in that it combines both [Adam](https://arxiv.org/abs/1412.6980), a popular variant of SGD, and layer-wise learning rates.\n",
    "\n",
    "**Exercise**: Use the NovoGrad optimizer.\n",
    "\n",
    "Replace the SGD optimizer with the NovoGrad optimizer and pass in the learning rate multiplied by the number of ranks. \n",
    "\n",
    "Look for `TODO: Step 10` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_10.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
